{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "749a7f99-7ae8-4d75-8089-fbc4e7c6b57a",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b03544ab-0116-44bb-a9c9-22851b707203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c06c84b-757d-472c-bb09-df7951a7da08",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5f491d-7c6f-4d64-b5fa-e3bc0a132db6",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b1146291-a095-4255-ae96-3cd1fd09c43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"CBIS-DDSM_Clean_Data/train_descriptions.csv\")\n",
    "test_df = pd.read_csv(\"CBIS-DDSM_Clean_Data/test_descriptions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5f8640b2-ba60-46c9-b5cc-3b106cb11b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2864 entries, 0 to 2863\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   breast_density    2864 non-null   int64 \n",
      " 1   breast_side       2864 non-null   object\n",
      " 2   image_view        2864 non-null   object\n",
      " 3   abnormality_type  2864 non-null   object\n",
      " 4   pathology         2864 non-null   object\n",
      " 5   series_uid        2864 non-null   object\n",
      " 6   images_new_paths  2864 non-null   object\n",
      " 7   image_type        2864 non-null   object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 179.1+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f515d840-ee76-41b2-bba2-b0e3d90b02e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 704 entries, 0 to 703\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   breast_density    704 non-null    int64 \n",
      " 1   breast_side       704 non-null    object\n",
      " 2   image_view        704 non-null    object\n",
      " 3   abnormality_type  704 non-null    object\n",
      " 4   pathology         704 non-null    object\n",
      " 5   series_uid        704 non-null    object\n",
      " 6   images_new_paths  704 non-null    object\n",
      " 7   image_type        704 non-null    object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 44.1+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5a241174-1d3c-44a7-9233-2246f641ae0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "breast_density                                                      3\n",
       "breast_side                                                      LEFT\n",
       "image_view                                                         CC\n",
       "abnormality_type                                                 mass\n",
       "pathology                                                   MALIGNANT\n",
       "series_uid          1.3.6.1.4.1.9590.100.1.2.342386194811267636608...\n",
       "images_new_paths    CBIS-DDSM_Clean_Data/images_png/1.3.6.1.4.1.95...\n",
       "image_type                                      full mammogram images\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "32ac6ec7-eed7-44f1-9e6b-49780fc9e478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data 2864\n",
      "Size of testing data 704\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of training data\", len(train_df))\n",
    "print(\"Size of testing data\", len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738a4a4e-8013-44e9-8d0a-62158bc999dd",
   "metadata": {},
   "source": [
    "### Encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9a96d1c1-3650-41c0-8945-cb102625e280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Encoded: \n",
      "['MALIGNANT' 'BENIGN' 'BENIGN_WITHOUT_CALLBACK']\n",
      "['MALIGNANT' 'BENIGN' 'BENIGN_WITHOUT_CALLBACK']\n",
      "\n",
      "Encoded: \n",
      "[2 0 1]\n",
      "[2 0 1]\n"
     ]
    }
   ],
   "source": [
    "# create dataframe and transform(encodes) pathology labels\n",
    "train_full_df = train_df\n",
    "test_full_df = test_df\n",
    "print(\"Non Encoded: \")\n",
    "print(train_full_df[\"pathology\"].unique())\n",
    "print(test_full_df[\"pathology\"].unique())\n",
    "print()\n",
    "\n",
    "train_full_df[\"label\"] = LabelEncoder().fit_transform(train_full_df[\"pathology\"]).astype(np.int32)\n",
    "test_full_df[\"label\"] = LabelEncoder().fit_transform(test_full_df[\"pathology\"]).astype(np.int32)\n",
    "\n",
    "print(\"Encoded: \")\n",
    "print(train_full_df[\"label\"].unique())\n",
    "print(test_full_df[\"label\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8e4d62-9aaa-47da-83ad-f0ee138f257b",
   "metadata": {},
   "source": [
    "### Split Training data into validation and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6be4609f-9982-4f97-8718-956a3f7b991e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set 2434\n",
      "Validation set 430\n",
      "Test set 704\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data = train_test_split(train_full_df, \n",
    "                                        test_size=0.15, \n",
    "                                        stratify=train_full_df[\"label\"], \n",
    "                                        random_state=42\n",
    "                                       )\n",
    "test_data = test_full_df.copy()\n",
    "\n",
    "print(\"Train set\", len(train_data))\n",
    "print(\"Validation set\", len(val_data))\n",
    "print(\"Test set\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84431e37-d4a0-4858-adc4-21f84bfde86d",
   "metadata": {},
   "source": [
    "## Create Tensors with dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec2a966-a16d-4332-beb3-13d079e42fc9",
   "metadata": {},
   "source": [
    "### Preprocess images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3e4da1fd-22f6-4556-a5e4-d16128331e94",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# function for preprocess images\n",
    "def img_preprocessing(path, img_size=(256, 256)):\n",
    "    # load image\n",
    "    image = load_img(path, color_mode='grayscale', target_size=img_size)\n",
    "\n",
    "    # normalize greyscale values between 0-1\n",
    "    image_arr = img_to_array(image) / 255.0 \n",
    "\n",
    "    return image_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4413be9c-2ba3-4c6f-afc7-71743c9dcd8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBIS-DDSM_Clean_Data/images_png/1.3.6.1.4.1.9590.100.1.2.3423861948112676366086941325904829245151-1.png\n"
     ]
    }
   ],
   "source": [
    "print(train_data[\"images_new_paths\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f2e09338-e125-4f60-b5b0-2077e96b8811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBIS-DDSM_Clean_Data/images_png/1.3.6.1.4.1.9590.100.1.2.3394399359126144235388160858318961541681-1.png\n",
      "Exists: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = train_data[\"images_new_paths\"].iloc[0]\n",
    "print(path)\n",
    "print(\"Exists:\", os.path.exists(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c6b7a0-f628-431d-8b42-9b7763a091a0",
   "metadata": {},
   "source": [
    "### Create tensors after preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "06f607bd-222e-4967-a4b9-bd2813750863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2434 validated image filenames.\n",
      "Found 430 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Generate dataset for processing \n",
    "\n",
    "# initiate generators\n",
    "t_generator = ImageDataGenerator()\n",
    "v_generator = ImageDataGenerator()\n",
    "\n",
    "# setup generators\n",
    "train_gen = t_generator.flow_from_dataframe(\n",
    "    dataframe=train_data,\n",
    "    x_col=\"images_new_paths\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(256, 256),\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=\"raw\",\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "val_gen = v_generator.flow_from_dataframe(\n",
    "    dataframe=val_data,\n",
    "    x_col=\"images_new_paths\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(256, 256),\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=\"raw\",\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3ae6d322-76de-483e-98be-de329d353b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 704 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_generator = ImageDataGenerator()\n",
    "\n",
    "# setup generators\n",
    "test_gen = test_generator.flow_from_dataframe(\n",
    "    dataframe=test_data,\n",
    "    x_col=\"images_new_paths\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(256, 256),\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=\"raw\",\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607693a8-e644-4644-9cd5-8c125b1a7f78",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed5d63b-3152-4715-8646-5d9542add9c3",
   "metadata": {},
   "source": [
    "### Model Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "60e130de-e86b-4c40-a1a9-95334699720d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model architecture function\n",
    "# ====== The following model architecture is based on  (Chollet, 2025, p. 216) =====\n",
    "def custom_Xray_CNN(input_shape, classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    model = models.Sequential([\n",
    "        inputs,\n",
    "        layers.Rescaling(1./255),                                           \n",
    "        layers.Conv2D(filters=32, kernel_size=3, activation='relu'),        # kernel size 3x3\n",
    "        layers.MaxPool2D(pool_size=2),                                      # pool size 2x2\n",
    "\n",
    "        layers.Conv2D(filters=64, kernel_size=3, activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=2),\n",
    "\n",
    "        layers.Conv2D(filters=128, kernel_size=3, activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=2),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(classes, activation='softmax')\n",
    "        \n",
    "    ])\n",
    "    model. compile(loss='sparse_categorical_crossentropy',\n",
    "                   optimizer='adam',\n",
    "                   metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39c622e-5994-4e61-90c9-d7742baf94ec",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5e7de3e1-799d-4872-8893-d435b57759ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model with an input image of 256x256 and 3 class labels\n",
    "model = custom_Xray_CNN((256, 256, 1), len(train_full_df[\"label\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f908322-5941-427c-b17a-1483122c11d2",
   "metadata": {},
   "source": [
    "### Fit Data to Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a79e7f8d-2f31-42f8-842e-30dfe8874c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5254 - loss: 0.9053"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/mayra/OneDrive/Documents/MayraCSc/AI/DQNvenv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 5s/step - accuracy: 0.5256 - loss: 0.9052 - val_accuracy: 0.5233 - val_loss: 0.9287\n",
      "Epoch 2/10\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 5s/step - accuracy: 0.6460 - loss: 0.7531 - val_accuracy: 0.5767 - val_loss: 0.8822\n",
      "Epoch 3/10\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 5s/step - accuracy: 0.7464 - loss: 0.6081 - val_accuracy: 0.5581 - val_loss: 0.9728\n",
      "Epoch 4/10\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 4s/step - accuracy: 0.8113 - loss: 0.4467 - val_accuracy: 0.5581 - val_loss: 1.0843\n",
      "Epoch 5/10\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 4s/step - accuracy: 0.8637 - loss: 0.3446 - val_accuracy: 0.5791 - val_loss: 1.2640\n",
      "Epoch 6/10\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4011s\u001b[0m 53s/step - accuracy: 0.8986 - loss: 0.2527 - val_accuracy: 0.5860 - val_loss: 1.3706\n",
      "Epoch 7/10\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 5s/step - accuracy: 0.9489 - loss: 0.1674 - val_accuracy: 0.6140 - val_loss: 1.5147\n",
      "Epoch 8/10\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 5s/step - accuracy: 0.9659 - loss: 0.1278 - val_accuracy: 0.5953 - val_loss: 1.7951\n",
      "Epoch 9/10\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 5s/step - accuracy: 0.9821 - loss: 0.0843 - val_accuracy: 0.5930 - val_loss: 1.8670\n",
      "Epoch 10/10\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 5s/step - accuracy: 0.9829 - loss: 0.0897 - val_accuracy: 0.6047 - val_loss: 1.8313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x76ae341cbd90>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit data to model\n",
    "history = model.fit(train_gen, validation_data=val_gen, epochs=10)\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "fd835e42-7210-4914-9c7b-0d5e9583df54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save history\n",
    "history_basic = pd.DataFrame(history.history)\n",
    "history_basic.to_csv(\"history_basic.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1ac4171c-fcf8-4148-a0f7-66f8f9b928a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 5s/step - accuracy: 0.5098 - loss: 2.4139\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "38f93a28-6ab2-49da-ae38-ea1fa2c05875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy in Test Data 0.4857954680919647\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Accuracy in Test Data\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660dcd95-cdde-4def-80c5-a372046c67b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DQNvenv)",
   "language": "python",
   "name": "dqnvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
