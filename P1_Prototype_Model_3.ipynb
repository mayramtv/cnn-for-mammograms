{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "749a7f99-7ae8-4d75-8089-fbc4e7c6b57a",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b03544ab-0116-44bb-a9c9-22851b707203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-28 19:13:37.375576: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-28 19:13:37.536209: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753744417.606389   18164 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753744417.640170   18164 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-28 19:13:37.820980: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c06c84b-757d-472c-bb09-df7951a7da08",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5f491d-7c6f-4d64-b5fa-e3bc0a132db6",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1146291-a095-4255-ae96-3cd1fd09c43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"CBIS-DDSM_Clean_Data/train_full.csv\")\n",
    "test_df = pd.read_csv(\"CBIS-DDSM_Clean_Data/test_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f8640b2-ba60-46c9-b5cc-3b106cb11b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2123 entries, 0 to 2122\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   image_id          2123 non-null   object \n",
      " 1   image_type        2123 non-null   object \n",
      " 2   image_path        2123 non-null   object \n",
      " 3   series_uid        2123 non-null   object \n",
      " 4   subject_id        2123 non-null   object \n",
      " 5   study_uid         2123 non-null   object \n",
      " 6   breast_density    2123 non-null   float64\n",
      " 7   breast_side       2123 non-null   object \n",
      " 8   image_view        2123 non-null   object \n",
      " 9   abnormality_type  2123 non-null   object \n",
      " 10  pathology         2123 non-null   object \n",
      " 11  split             2123 non-null   object \n",
      "dtypes: float64(1), object(11)\n",
      "memory usage: 199.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f515d840-ee76-41b2-bba2-b0e3d90b02e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 562 entries, 0 to 561\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   image_id          562 non-null    object \n",
      " 1   image_type        562 non-null    object \n",
      " 2   image_path        562 non-null    object \n",
      " 3   series_uid        562 non-null    object \n",
      " 4   subject_id        562 non-null    object \n",
      " 5   study_uid         562 non-null    object \n",
      " 6   breast_density    562 non-null    float64\n",
      " 7   breast_side       562 non-null    object \n",
      " 8   image_view        562 non-null    object \n",
      " 9   abnormality_type  562 non-null    object \n",
      " 10  pathology         562 non-null    object \n",
      " 11  split             562 non-null    object \n",
      "dtypes: float64(1), object(11)\n",
      "memory usage: 52.8+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a241174-1d3c-44a7-9233-2246f641ae0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_id                                                     51547_00\n",
       "image_type                                                       full\n",
       "image_path          CBIS-DDSM_Clean_Data/labeled_images_png/1.3.6....\n",
       "series_uid          1.3.6.1.4.1.9590.100.1.2.100131208110604806117...\n",
       "subject_id                              Calc-Training_P_01107_LEFT_CC\n",
       "study_uid           1.3.6.1.4.1.9590.100.1.2.113816182611334006337...\n",
       "breast_density                                                    2.0\n",
       "breast_side                                                      LEFT\n",
       "image_view                                                         CC\n",
       "abnormality_type                                        calcification\n",
       "pathology                                                      BENIGN\n",
       "split                                                           train\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32ac6ec7-eed7-44f1-9e6b-49780fc9e478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data 2123\n",
      "Size of testing data 562\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of training data\", len(train_df))\n",
    "print(\"Size of testing data\", len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738a4a4e-8013-44e9-8d0a-62158bc999dd",
   "metadata": {},
   "source": [
    "### Encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a96d1c1-3650-41c0-8945-cb102625e280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Encoded: \n",
      "['BENIGN' 'MALIGNANT']\n",
      "['MALIGNANT' 'BENIGN']\n",
      "\n",
      "Encoded: \n",
      "[0 1]\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "# create dataframe and transform(encodes) pathology labels\n",
    "train_full_df = train_df\n",
    "test_full_df = test_df\n",
    "print(\"Non Encoded: \")\n",
    "print(train_full_df[\"pathology\"].unique())\n",
    "print(test_full_df[\"pathology\"].unique())\n",
    "print()\n",
    "\n",
    "train_full_df[\"label\"] = LabelEncoder().fit_transform(train_full_df[\"pathology\"]).astype(np.int32)\n",
    "test_full_df[\"label\"] = LabelEncoder().fit_transform(test_full_df[\"pathology\"]).astype(np.int32)\n",
    "\n",
    "print(\"Encoded: \")\n",
    "print(train_full_df[\"label\"].unique())\n",
    "print(test_full_df[\"label\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8e4d62-9aaa-47da-83ad-f0ee138f257b",
   "metadata": {},
   "source": [
    "### Split training data into validation and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6be4609f-9982-4f97-8718-956a3f7b991e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set 1804\n",
      "Validation set 319\n",
      "Test set 562\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data = train_test_split(train_full_df, \n",
    "                                        test_size=0.15, \n",
    "                                        stratify=train_full_df[\"label\"], \n",
    "                                        random_state=42\n",
    "                                       )\n",
    "test_data = test_full_df.copy()\n",
    "\n",
    "print(\"Train set\", len(train_data))\n",
    "print(\"Validation set\", len(val_data))\n",
    "print(\"Test set\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84431e37-d4a0-4858-adc4-21f84bfde86d",
   "metadata": {},
   "source": [
    "## Create tensors with dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec2a966-a16d-4332-beb3-13d079e42fc9",
   "metadata": {},
   "source": [
    "### Preprocess images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e4da1fd-22f6-4556-a5e4-d16128331e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for preprocess images\n",
    "def img_preprocessing(path, img_size=(256, 256)):\n",
    "    # load image\n",
    "    image = load_img(path, color_mode='grayscale', target_size=img_size)\n",
    "\n",
    "    # normalize greyscale values between 0-1\n",
    "    image_arr = img_to_array(image) / 255.0 \n",
    "\n",
    "    return image_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4413be9c-2ba3-4c6f-afc7-71743c9dcd8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBIS-DDSM_Clean_Data/labeled_images_png/1.3.6.1.4.1.9590.100.1.2.100131208110604806117271735422083351547_full.png\n"
     ]
    }
   ],
   "source": [
    "print(train_data[\"image_path\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2e09338-e125-4f60-b5b0-2077e96b8811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBIS-DDSM_Clean_Data/labeled_images_png/1.3.6.1.4.1.9590.100.1.2.100131208110604806117271735422083351547_full.png\n",
      "Exists: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = train_data[\"image_path\"][0]\n",
    "print(path)\n",
    "print(\"Exists:\", os.path.exists(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c6b7a0-f628-431d-8b42-9b7763a091a0",
   "metadata": {},
   "source": [
    "### Create iterators(generators) after preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06f607bd-222e-4967-a4b9-bd2813750863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1804 validated image filenames.\n",
      "Found 319 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Generate dataset for processing \n",
    "\n",
    "# initiate generators\n",
    "t_generator = ImageDataGenerator()\n",
    "v_generator = ImageDataGenerator()\n",
    "\n",
    "# setup generators\n",
    "train_gen = t_generator.flow_from_dataframe(\n",
    "    dataframe=train_data,\n",
    "    x_col=\"image_path\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(256, 256),\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=\"raw\",\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "val_gen = v_generator.flow_from_dataframe(\n",
    "    dataframe=val_data,\n",
    "    x_col=\"image_path\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(256, 256),\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=\"raw\",\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ae6d322-76de-483e-98be-de329d353b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 562 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_generator = ImageDataGenerator()\n",
    "\n",
    "# setup generators\n",
    "test_gen = test_generator.flow_from_dataframe(\n",
    "    dataframe=test_data,\n",
    "    x_col=\"image_path\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(256, 256),\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=\"raw\",\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607693a8-e644-4644-9cd5-8c125b1a7f78",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed5d63b-3152-4715-8646-5d9542add9c3",
   "metadata": {},
   "source": [
    "### Model Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60e130de-e86b-4c40-a1a9-95334699720d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model architecture function\n",
    "# ====== The following model architecture is based on  (Chollet, 2025, p. 216) =====\n",
    "def custom_Xray_CNN(input_shape, classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    model = models.Sequential([\n",
    "        inputs,\n",
    "        layers.Rescaling(1./255),                                           \n",
    "        layers.Conv2D(filters=32, kernel_size=3, activation='relu'),        # kernel size 3x3\n",
    "        layers.MaxPool2D(pool_size=2),                                      # pool size 2x2\n",
    "\n",
    "        layers.Conv2D(filters=64, kernel_size=3, activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=2),\n",
    "\n",
    "        layers.Conv2D(filters=128, kernel_size=3, activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=2),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(classes, activation='softmax')\n",
    "        \n",
    "    ])\n",
    "    model. compile(loss='sparse_categorical_crossentropy',\n",
    "                   optimizer='adam',\n",
    "                   metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39c622e-5994-4e61-90c9-d7742baf94ec",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e7de3e1-799d-4872-8893-d435b57759ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753744606.428519   18164 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "# train model with an input image of 256x256 and 3 class labels\n",
    "model = custom_Xray_CNN((256, 256, 1), len(train_full_df[\"label\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f908322-5941-427c-b17a-1483122c11d2",
   "metadata": {},
   "source": [
    "### Fit Data to Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79e7f8d-2f31-42f8-842e-30dfe8874c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/mayra/OneDrive/Documents/MayraCSc/AI/DQNvenv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1753744626.250482   18359 service.cc:148] XLA service 0x7360cc00a790 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1753744626.250718   18359 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
      "2025-07-28 19:17:06.296299: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1753744626.406881   18359 cuda_dnn.cc:529] Loaded cuDNN version 90501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 2/57\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.4531 - loss: 0.7008  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753744631.275974   18359 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 6s/step - accuracy: 0.5082 - loss: 0.6932 - val_accuracy: 0.4984 - val_loss: 0.6846\n",
      "Epoch 2/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 6s/step - accuracy: 0.5747 - loss: 0.6696 - val_accuracy: 0.5517 - val_loss: 0.6822\n",
      "Epoch 3/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 6s/step - accuracy: 0.6241 - loss: 0.6445 - val_accuracy: 0.5329 - val_loss: 0.6711\n",
      "Epoch 4/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 6s/step - accuracy: 0.6805 - loss: 0.5962 - val_accuracy: 0.5768 - val_loss: 0.7161\n",
      "Epoch 5/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 6s/step - accuracy: 0.7619 - loss: 0.4749 - val_accuracy: 0.5831 - val_loss: 0.7609\n",
      "Epoch 6/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11778s\u001b[0m 210s/step - accuracy: 0.8072 - loss: 0.3951 - val_accuracy: 0.5831 - val_loss: 0.9505\n",
      "Epoch 7/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 6s/step - accuracy: 0.8491 - loss: 0.3126 - val_accuracy: 0.5674 - val_loss: 1.0963\n",
      "Epoch 8/10\n",
      "\u001b[1m21/57\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m3:34\u001b[0m 6s/step - accuracy: 0.9019 - loss: 0.2514"
     ]
    }
   ],
   "source": [
    "# fit data to model\n",
    "history = model.fit(train_gen, validation_data=val_gen, epochs=10)\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd835e42-7210-4914-9c7b-0d5e9583df54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save history\n",
    "history_basic = pd.DataFrame(history.history)\n",
    "history_basic.to_csv(\"Outputs/binary_history_basic.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac4171c-fcf8-4148-a0f7-66f8f9b928a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f93a28-6ab2-49da-ae38-ea1fa2c05875",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model Accuracy in Test Data\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660dcd95-cdde-4def-80c5-a372046c67b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DQNvenv)",
   "language": "python",
   "name": "dqnvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
