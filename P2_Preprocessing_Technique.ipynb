{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50e99e55-341e-43da-8c1f-afee52bb0e3c",
   "metadata": {},
   "source": [
    "## Phase 2: Find Processing Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96fd6e95-d1fa-48f2-bd0c-3bef4f9577fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3721b79-5019-4f5a-916a-a709f08ae1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class -> Try if python utils connects to notebook: My_Test_Class \n",
      "\n",
      "Function -> Try if python utils connects to notebook: My_Test_Function\n"
     ]
    }
   ],
   "source": [
    "# connects to utils and run a test for connectivity\n",
    "from Utils.test_class_func import Test_py \n",
    "from Utils.test_class_func import test_py  \n",
    "print(Test_py(\"My_Test_Class\").print_(), \"\\n\")\n",
    "print(test_py(\"My_Test_Function\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbec7fd7-6fc7-4346-ae93-4d26542a2e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 11:53:23.883264: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-20 11:53:23.915993: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755705203.934492   30737 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755705203.940276   30737 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-20 11:53:23.968992: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# import functions \n",
    "from Utils.preporcessing_utils import data_loading \n",
    "from Utils.preporcessing_utils import labels_encoding\n",
    "from Utils.preporcessing_utils import split_data\n",
    "from Utils.preporcessing_utils import image_iterators\n",
    "from Utils.preporcessing_utils import ablation\n",
    "from Utils.models_utils import Basic_Custom_CNN\n",
    "from Utils.evaluation_utils import Evaluation\n",
    "from Utils.save_data_utils import Save_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fc3f4e7-0e09-4cb6-a4dd-38af1616dba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d801ef-a7c3-4803-bd18-3c8b0c1633e3",
   "metadata": {},
   "source": [
    "### Pipeline Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d45554-3efd-41ca-b5b0-8e68c3b7de7f",
   "metadata": {},
   "source": [
    "#### Data Preparation and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33cd2722-e9fc-41e5-87fa-0d54425feec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads data\n",
    "train_df, test_df = data_loading(\"train_full.csv\", \"test_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5b047f1-562e-410c-a183-5745bdfca878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe and transform(encodes) pathology labels\n",
    "train_df, test_df = labels_encoding(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beb30fc9-9569-40f2-9b0c-1095bafa070d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_id', 'image_type', 'image_path', 'series_uid', 'subject_id',\n",
       "       'study_uid', 'breast_density', 'breast_side', 'image_view',\n",
       "       'abnormality_type', 'pathology', 'split', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abc2cb65-26ed-4787-bb71-d66af7b29445",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 1889 cases, 70.35 %\n",
      "Validation set: 234 cases, 8.72 %\n",
      "Test set: 562 cases, 20.93 %\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "train_data, val_data, test_data = split_data(train_df, test_df, 0.11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e728c2a8-ebf2-4a14-a059-4d6c86eafbde",
   "metadata": {},
   "source": [
    "#### Iteration 1: Finding best preprocessing technique using custom CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a806ec0b-0461-449b-8323-b688fdf7e77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables \n",
    "project_phase = \"P2\"\n",
    "options = ['apply_background_removal',\n",
    "           'apply_crop',\n",
    "           'apply_noise_reduction',\n",
    "           'apply_contrast_enhancement',\n",
    "           'apply_edge_enhancement',\n",
    "           'apply_lbp_texturizer']\n",
    "\n",
    "y_true = test_data[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c526edd3-7ae2-433e-8008-af0a6d8be615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create group of techniques to try\n",
    "techniques_groups = ablation(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2bc0106-c314-42ce-b165-fbc49d9cad65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Baseline Basic Preporcessing': {'apply_background_removal': False,\n",
       "  'apply_crop': False,\n",
       "  'apply_noise_reduction': False,\n",
       "  'apply_contrast_enhancement': False,\n",
       "  'apply_edge_enhancement': False,\n",
       "  'apply_lbp_texturizer': False},\n",
       " 'All Preporcessing Techniques': {'apply_background_removal': True,\n",
       "  'apply_crop': True,\n",
       "  'apply_noise_reduction': True,\n",
       "  'apply_contrast_enhancement': True,\n",
       "  'apply_edge_enhancement': True,\n",
       "  'apply_lbp_texturizer': True},\n",
       " 'No Background removal': {'apply_background_removal': False,\n",
       "  'apply_crop': True,\n",
       "  'apply_noise_reduction': True,\n",
       "  'apply_contrast_enhancement': True,\n",
       "  'apply_edge_enhancement': True,\n",
       "  'apply_lbp_texturizer': True},\n",
       " 'No Crop': {'apply_background_removal': True,\n",
       "  'apply_crop': False,\n",
       "  'apply_noise_reduction': True,\n",
       "  'apply_contrast_enhancement': True,\n",
       "  'apply_edge_enhancement': True,\n",
       "  'apply_lbp_texturizer': True},\n",
       " 'No Noise reduction': {'apply_background_removal': True,\n",
       "  'apply_crop': True,\n",
       "  'apply_noise_reduction': False,\n",
       "  'apply_contrast_enhancement': True,\n",
       "  'apply_edge_enhancement': True,\n",
       "  'apply_lbp_texturizer': True},\n",
       " 'No Contrast enhancement': {'apply_background_removal': True,\n",
       "  'apply_crop': True,\n",
       "  'apply_noise_reduction': True,\n",
       "  'apply_contrast_enhancement': False,\n",
       "  'apply_edge_enhancement': True,\n",
       "  'apply_lbp_texturizer': True},\n",
       " 'No Edge enhancement': {'apply_background_removal': True,\n",
       "  'apply_crop': True,\n",
       "  'apply_noise_reduction': True,\n",
       "  'apply_contrast_enhancement': True,\n",
       "  'apply_edge_enhancement': False,\n",
       "  'apply_lbp_texturizer': True},\n",
       " 'No Lbp texturizer': {'apply_background_removal': True,\n",
       "  'apply_crop': True,\n",
       "  'apply_noise_reduction': True,\n",
       "  'apply_contrast_enhancement': True,\n",
       "  'apply_edge_enhancement': True,\n",
       "  'apply_lbp_texturizer': False}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "techniques_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d3c437b-5137-4802-9aa0-cc470523a1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Custom CNN - Baseline Basic Preporcessing\n",
      "Found 1889 validated image filenames.\n",
      "Found 234 validated image filenames.\n",
      "Found 562 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755705390.946366   30737 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "/mnt/c/Users/mayra/OneDrive/Documents/MayraCSc/AI/DQNvenv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1755705414.483434   30943 service.cc:148] XLA service 0x70c67800ac90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1755705414.483494   30943 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
      "2025-08-20 11:56:54.515680: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1755705414.662412   30943 cuda_dnn.cc:529] Loaded cuDNN version 90501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/60\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14:22\u001b[0m 15s/step - accuracy: 0.5000 - auc: 0.5000 - loss: 0.6932 - precision: 0.5000 - recall: 0.1250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755705418.956087   30943 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m514s\u001b[0m 8s/step - accuracy: 0.5252 - auc: 0.5000 - loss: 0.6931 - precision: 0.5294 - recall: 0.9290 - val_accuracy: 0.5171 - val_auc: 0.5000 - val_loss: 0.6931 - val_precision: 0.5171 - val_recall: 1.0000\n",
      "Epoch 2/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m378s\u001b[0m 6s/step - accuracy: 0.5268 - auc: 0.4994 - loss: 0.6928 - precision: 0.5268 - recall: 1.0000 - val_accuracy: 0.5171 - val_auc: 0.5000 - val_loss: 0.6930 - val_precision: 0.5171 - val_recall: 1.0000\n",
      "Epoch 3/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 7s/step - accuracy: 0.5084 - auc: 0.5036 - loss: 0.6930 - precision: 0.5084 - recall: 1.0000 - val_accuracy: 0.5171 - val_auc: 0.5000 - val_loss: 0.6926 - val_precision: 0.5171 - val_recall: 1.0000\n",
      "Epoch 4/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 8s/step - accuracy: 0.5346 - auc: 0.4881 - loss: 0.6917 - precision: 0.5346 - recall: 1.0000 - val_accuracy: 0.5171 - val_auc: 0.5000 - val_loss: 0.6928 - val_precision: 0.5171 - val_recall: 1.0000\n",
      "Epoch 5/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m402s\u001b[0m 7s/step - accuracy: 0.5356 - auc: 0.4827 - loss: 0.6924 - precision: 0.5356 - recall: 1.0000 - val_accuracy: 0.5171 - val_auc: 0.4642 - val_loss: 0.6926 - val_precision: 0.5171 - val_recall: 1.0000\n",
      "Epoch 6/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 8s/step - accuracy: 0.5146 - auc: 0.5107 - loss: 0.6927 - precision: 0.5146 - recall: 1.0000 - val_accuracy: 0.5171 - val_auc: 0.4997 - val_loss: 0.6927 - val_precision: 0.5171 - val_recall: 1.0000\n",
      "Epoch 7/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 6s/step - accuracy: 0.5087 - auc: 0.4877 - loss: 0.6937 - precision: 0.5087 - recall: 1.0000 - val_accuracy: 0.5171 - val_auc: 0.5385 - val_loss: 0.6927 - val_precision: 0.5171 - val_recall: 1.0000\n",
      "Epoch 8/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m394s\u001b[0m 6s/step - accuracy: 0.5296 - auc: 0.5164 - loss: 0.6924 - precision: 0.5296 - recall: 1.0000 - val_accuracy: 0.5171 - val_auc: 0.4988 - val_loss: 0.6926 - val_precision: 0.5171 - val_recall: 1.0000\n",
      "Epoch 9/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 6s/step - accuracy: 0.5210 - auc: 0.5051 - loss: 0.6925 - precision: 0.5210 - recall: 1.0000 - val_accuracy: 0.5171 - val_auc: 0.4799 - val_loss: 0.6926 - val_precision: 0.5171 - val_recall: 1.0000\n",
      "Epoch 10/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 7s/step - accuracy: 0.5181 - auc: 0.5024 - loss: 0.6927 - precision: 0.5181 - recall: 1.0000 - val_accuracy: 0.5171 - val_auc: 0.5261 - val_loss: 0.6926 - val_precision: 0.5171 - val_recall: 1.0000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 5s/step\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'posixpath' has no attribute 'exist'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m y_labels \u001b[38;5;241m=\u001b[39m evaluation\u001b[38;5;241m.\u001b[39mget_labels()\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# save data\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m save_data \u001b[38;5;241m=\u001b[39m \u001b[43mSave_Data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels_data.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOutputs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m save_data\u001b[38;5;241m.\u001b[39madd_model_data(model_name, model_path, history, metrics, y_labels, project_phase, comments\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m save_data\u001b[38;5;241m.\u001b[39msave_model_data()\n",
      "File \u001b[0;32m/mnt/c/Users/mayra/OneDrive/Documents/MayraCSc/FP/cnn-for-mammograms/Utils/save_data_utils.py:17\u001b[0m, in \u001b[0;36mSave_Data.__init__\u001b[0;34m(self, file_name, out_directory)\u001b[0m\n\u001b[1;32m     14\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(out_directory, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# open json file, if exist, to load existing output data\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexist\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'posixpath' has no attribute 'exist'"
     ]
    }
   ],
   "source": [
    "# iterate trough techniques groups for training a model with each group\n",
    "for technique_name, techniques in techniques_groups.items():\n",
    "    \n",
    "    # create model name\n",
    "    model_name = \"Custom CNN - \" + technique_name\n",
    "    print(\"Training \" + model_name)\n",
    "    \n",
    "    # reset and clears variables before creating a new model \n",
    "    K.clear_session()\n",
    "    \n",
    "    # Create image iterators with preprocessing function for each set of preprocessing techniques \n",
    "    train_generator, val_generator, test_generator = image_iterators((train_data, val_data, test_data), \n",
    "                                                    is_resnet_vgg=False,\n",
    "                                                    preprocessing_techniques=techniques\n",
    "                                                  )\n",
    "    \n",
    "    # initiate model class\n",
    "    model_instance = Basic_Custom_CNN(input_shape=(256, 256, 1), num_classes=2, epochs=10)\n",
    "    \n",
    "    # create model architecture\n",
    "    model_instance.architecture()\n",
    "    \n",
    "    # train model\n",
    "    history = model_instance.train_model(train_generator, val_gen=val_generator)\n",
    "    \n",
    "    # save model and get path\n",
    "    name = technique_name.lower().replace(\" \", \"_\") + \".keras\"\n",
    "    model_path = model_instance.save_model(models_directory=\"Models\", model_file=name)\n",
    "\n",
    "    # evaluate model by making predictions\n",
    "    evaluation = Evaluation(model_instance.get_model())\n",
    "    y_probs = evaluation.predict(test_generator)\n",
    "\n",
    "    # calculate metrics\n",
    "    metrics = evaluation.calculate_metrics(y_true, y_probs)\n",
    "\n",
    "    # get labels dictionary\n",
    "    y_labels = evaluation.get_labels()\n",
    "\n",
    "    # save data\n",
    "    save_data = Save_Data(file_name=\"models_data.json\", out_directory=\"Outputs\")\n",
    "    save_data.add_model_data(model_name, model_path, history, metrics, y_labels, project_phase, comments=\"\")\n",
    "    save_data.save_model_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc37c08a-54ea-45a8-932f-80be70e61c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 1. Get predictions for the test set\n",
    "y_probs = evaluation.predict(test_generator)\n",
    "y_true = test_generator.labels\n",
    "\n",
    "# 2. Flatten predictions if sigmoid output\n",
    "y_probs = y_probs.ravel()\n",
    "\n",
    "# 3. Separate probabilities by class\n",
    "pos_probs = y_probs[y_true == 1]  # predicted probs for actual positives\n",
    "neg_probs = y_probs[y_true == 0]  # predicted probs for actual negatives\n",
    "\n",
    "# 4. Plot histograms\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(neg_probs, bins=20, alpha=0.6, label=\"Class 0 (negatives)\")\n",
    "plt.hist(pos_probs, bins=20, alpha=0.6, label=\"Class 1 (positives)\")\n",
    "plt.axvline(0.5, color='red', linestyle='--', label=\"Decision threshold 0.5\")\n",
    "\n",
    "plt.xlabel(\"Predicted probability for class 1\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of predicted probabilities\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b751e66-c015-4ab6-964b-cad101ece0ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff751fa6-1d36-437b-917e-a9ed17f50c36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 6s/step\n",
      "[[0.51568824]\n",
      " [0.42866644]\n",
      " [0.57756436]\n",
      " [0.48283404]\n",
      " [0.39064458]]\n"
     ]
    }
   ],
   "source": [
    "y_p = evaluation.predict(test_generator)\n",
    "print(y_p[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57425912-b770-48df-86da-67cbecf6962b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'confusion_matrix': array([[  0, 302],\n",
       "        [  0, 260]]),\n",
       " 'accuracy': 0.4626334519572954,\n",
       " 'precision': 0.4626334519572954,\n",
       " 'recall': 1.0,\n",
       " 'f1_score': 0.6326034063260341,\n",
       " 'roc_auc': 0.5280883851248089,\n",
       " 'specificity': np.float64(0.0),\n",
       " 'fpr': np.float64(1.0),\n",
       " 'fnr': np.float64(0.0)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cd14997-09cd-414f-b28d-59cd4abcdaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{np.int32(0): np.int64(302), np.int32(1): np.int64(260)}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "unique, counts = np.unique(test_data[\"label\"], return_counts=True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b31438-a44f-4276-810a-f88a171329f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808fefb0-6ede-4425-854b-6307c54f6bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(train_data[\"label\"], return_counts=True))\n",
    "print(np.unique(test_data[\"label\"], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454b1cf7-2733-43fc-9af4-75e2414a7cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "915e5d13-5ed7-47b4-86d9-be1b8b2b5789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (array([0, 1], dtype=int32), array([912, 977]))\n",
      "Val: (array([0, 1], dtype=int32), array([113, 121]))\n",
      "Test: (array([0, 1], dtype=int32), array([302, 260]))\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\", np.unique(train_generator.labels, return_counts=True))\n",
    "print(\"Val:\", np.unique(val_generator.labels, return_counts=True))\n",
    "print(\"Test:\", np.unique(test_generator.labels, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0905fc72-8925-4624-9bfa-cd3984c06989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X batch range: 0.0 to 1.0\n",
      "Y batch sample: [1 0 1 0 1 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "x_batch, y_batch = next(iter(train_generator))\n",
    "print(\"X batch range:\", x_batch.min(), \"to\", x_batch.max())\n",
    "print(\"Y batch sample:\", y_batch[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d63935e-eb98-4c40-aa9f-c4fc73349890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b69c40-4480-4e45-8df1-83b5905cbefb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DQNvenv)",
   "language": "python",
   "name": "dqnvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
